{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d20d8859",
   "metadata": {},
   "source": [
    "1.0 Data Pipeline Execution and Initial EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dbc206",
   "metadata": {},
   "source": [
    "This notebook executes the data scraping, cleaning, and initial sentiment scoring, preparing the dataset for detailed analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b5f6d",
   "metadata": {},
   "source": [
    "First, we ensure all necessary modules from our src folder are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aedfd88a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to system path: D:\\Projects\\Sentiment-Analysis-Influencer-Controversies\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.data_scraper'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m-------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProject root added to system path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_root_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# ----------------------------------------------------------------\u001b[39;00m\n\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Import our custom modules\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_scraper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_data_pipeline, save_data\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msentiment_analyzer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m analyze_sentiment, save_processed_data\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Set display options\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src.data_scraper'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- ROBUST FIX: Adding Project Root to System Path ---\n",
    "# We are currently in 'notebooks/'. We need to add the parent directory to the path.\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the path to the current notebook's directory (e.g., .../notebooks)\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the path to the project root (the directory containing 'src' and 'notebooks')\n",
    "project_root_path = os.path.dirname(current_dir)\n",
    "\n",
    "# Add the project root to the system path\n",
    "sys.path.append(project_root_path)\n",
    "\n",
    "# Verification: Print the path being added\n",
    "print(f\"Project root added to system path: {project_root_path}\")\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# Import our custom modules\n",
    "from src.data_scraper import run_data_pipeline, save_data\n",
    "from src.sentiment_analyzer import analyze_sentiment, save_processed_data\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb692b7",
   "metadata": {},
   "source": [
    "2. Data Acquisition\n",
    "\n",
    "We run the core scraping function. Note: This uses mock data generation, as a real YouTube API key is required for actual scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d54898a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_data_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m-------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m RAW_FILE_NAME = \u001b[33m\"\u001b[39m\u001b[33mtarte_raw_comments.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Run the data pipeline (uses mock data generated in src/data_scraper.py)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df_raw = \u001b[43mrun_data_pipeline\u001b[49m(CONTROVERSY_NAME)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal raw comments collected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_raw)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Save the raw data\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'run_data_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# --- PARAMETERS ---\n",
    "CONTROVERSY_NAME = \"The Tarte Brand Trip Scandal\"\n",
    "RAW_FILE_NAME = \"tarte_raw_comments.csv\"\n",
    "\n",
    "# Run the data pipeline (uses mock data generated in src/data_scraper.py)\n",
    "df_raw = run_data_pipeline(CONTROVERSY_NAME)\n",
    "print(f\"Total raw comments collected: {len(df_raw)}\")\n",
    "\n",
    "# Save the raw data\n",
    "save_data(df_raw, RAW_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07041a65",
   "metadata": {},
   "source": [
    "3. Sentiment Analysis Execution\n",
    "\n",
    "We now run the full sentiment analysis, applying both VADER and TextBlob to all comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb90897",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analyze_sentiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m-------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run the full sentiment analysis and cleaning pipeline\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_processed = \u001b[43manalyze_sentiment\u001b[49m(df_raw.copy())\n\u001b[32m      3\u001b[39m PROCESSED_FILE_NAME = \u001b[33m\"\u001b[39m\u001b[33mtarte_processed_sentiment.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Save the processed data for subsequent notebooks\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'analyze_sentiment' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the full sentiment analysis and cleaning pipeline\n",
    "df_processed = analyze_sentiment(df_raw.copy())\n",
    "PROCESSED_FILE_NAME = \"tarte_processed_sentiment.csv\"\n",
    "\n",
    "# Save the processed data for subsequent notebooks\n",
    "save_processed_data(df_processed, PROCESSED_FILE_NAME)\n",
    "\n",
    "print(\"\\n--- Processed Data Snapshot ---\")\n",
    "df_processed[['comment_text', 'vader_compound', 'textblob_polarity', 'textblob_subjectivity']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056d02e",
   "metadata": {},
   "source": [
    "4. Initial Exploratory Data Analysis (EDA)\n",
    "\n",
    "A quick look at the distribution of engagement and preliminary VADER scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a17e645",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m-------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Distribution of Comment Likes (Engagement)\u001b[39;00m\n\u001b[32m      2\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m sns.histplot(\u001b[43mdf_processed\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mcomment_likes\u001b[39m\u001b[33m'\u001b[39m], bins=\u001b[32m50\u001b[39m, kde=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mDistribution of Comment Likes (Engagement)\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mComment Likes\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_processed' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of Comment Likes (Engagement)\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_processed['comment_likes'], bins=50, kde=True)\n",
    "plt.title('Distribution of Comment Likes (Engagement)')\n",
    "plt.xlabel('Comment Likes')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34ffb1c9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m-------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Preliminary VADER Compound Score Distribution\u001b[39;00m\n\u001b[32m      2\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m sns.histplot(\u001b[43mdf_processed\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mvader_compound\u001b[39m\u001b[33m'\u001b[39m], bins=\u001b[32m30\u001b[39m, kde=\u001b[38;5;28;01mTrue\u001b[39;00m, color=\u001b[33m'\u001b[39m\u001b[33mskyblue\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mDistribution of VADER Compound Scores\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mVADER Compound Score (-1.0 to +1.0)\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_processed' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preliminary VADER Compound Score Distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_processed['vader_compound'], bins=30, kde=True, color='skyblue')\n",
    "plt.title('Distribution of VADER Compound Scores')\n",
    "plt.xlabel('VADER Compound Score (-1.0 to +1.0)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Final status update\n",
    "print(f\"Data pipeline complete. Processed data ready in data/processed/{PROCESSED_FILE_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc5705-5ac2-4179-be32-10e22ca85e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83954f04-e155-4a8d-81d9-1ac73d1f1578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ccd39-53fe-456e-a1b9-372fc18abc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66dfe36-fe5f-4bc6-9398-84441fb3e7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
